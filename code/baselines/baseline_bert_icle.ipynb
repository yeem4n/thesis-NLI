{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ifj6zqTMeyvi"
   },
   "source": [
    "# BERT for ICLE dataset\n",
    "This notebook contains the code to fine-tune BERT for the ICLE-NLI dataset. We evaluate under five-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TuOTIkbHpAr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57uX4Y2zRuOf"
   },
   "source": [
    "# BERT ICLE 5CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yh1LONeIB5Ci",
    "outputId": "4dd593d9-4edf-43be-f695-854b665b01f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/5\n",
      "Num predictions: 154\n",
      "Accuracy for Fold 1: 0.8116883116883117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 2/5\n",
      "Num predictions: 308\n",
      "Accuracy for Fold 2: 0.7467532467532467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 3/5\n",
      "Num predictions: 462\n",
      "Accuracy for Fold 3: 0.7987012987012987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 4/5\n",
      "Num predictions: 616\n",
      "Accuracy for Fold 4: 0.7857142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 5/5\n",
      "Num predictions: 770\n",
      "Accuracy for Fold 5: 0.7727272727272727\n",
      "Average Accuracy: 0.7831168831168831\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: \"BUL\", 1: \"CHI\", 2: \"CZE\", 3: \"FRE\", 4: \"JPN\", 5: \"RUS\", 6: \"SPA\"}\n",
    "label2id = {\"BUL\": 0, \"CHI\": 1, \"CZE\": 2, \"FRE\": 3, \"JPN\": 4, \"RUS\": 5, \"SPA\": 6}\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = tokenizer(text, padding='max_length', truncation=True, max_length=510, return_tensors='pt')\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': torch.tensor(label2id[label])}\n",
    "\n",
    "# convert dataframe to dataset\n",
    "icle = \"/content/drive/MyDrive/thesis_NLI/ICLE-NLI-results.csv\"\n",
    "df = pd.read_csv(icle)\n",
    "dataset = TextDataset(df['text'].tolist(), df['language'].tolist())\n",
    "\n",
    "# 5-fold cv\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=1)\n",
    "\n",
    "# lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "predictions = {}\n",
    "\n",
    "# perform 5-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['text'], df['language'])):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7, id2label=id2label, label2id=label2id)\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # train and test sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "    # create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=12, shuffle=False)\n",
    "\n",
    "    # training\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(12):  # 12 epochs\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # evaluation\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1) # get predicted values\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "        for predicted_label, test_index in zip(val_predictions, val_indices):\n",
    "            predicted_lang = id2label[predicted_label] # get predicted labels\n",
    "            predictions[test_index] = predicted_lang\n",
    "    print(f\"Num predictions: {len(predictions)}\")\n",
    "    model.save_pretrained(f\"/content/drive/MyDrive/thesis_NLI/ICLE/finetuned_bert_{fold}\") # Local saving\n",
    "    tokenizer.save_pretrained(f\"/content/drive/MyDrive/thesis_NLI/ICLE/finetuned_bert_{fold}\")\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "# calculate average accuracy across all folds\n",
    "average_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "print(f\"Average Accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQCFxgwVSFwG"
   },
   "source": [
    "# Add results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmfASB-9W0O5",
    "outputId": "871855b8-12ed-4f9e-bfb8-7c7f0faa0f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(0, 'RUS'), (1, 'RUS'), (2, 'CHI'), (3, 'BUL'), (4, 'BUL'), (5, 'BUL'), (6, 'BUL'), (7, 'BUL'), (8, 'FRE'), (9, 'BUL'), (10, 'BUL'), (11, 'BUL'), (12, 'FRE'), (13, 'FRE'), (14, 'RUS'), (15, 'BUL'), (16, 'RUS'), (17, 'CZE'), (18, 'BUL'), (19, 'BUL'), (20, 'BUL'), (21, 'BUL'), (22, 'BUL'), (23, 'CZE'), (24, 'BUL'), (25, 'FRE'), (26, 'BUL'), (27, 'BUL'), (28, 'BUL'), (29, 'BUL'), (30, 'BUL'), (31, 'FRE'), (32, 'BUL'), (33, 'BUL'), (34, 'BUL'), (35, 'BUL'), (36, 'BUL'), (37, 'BUL'), (38, 'CZE'), (39, 'BUL'), (40, 'BUL'), (41, 'BUL'), (42, 'BUL'), (43, 'BUL'), (44, 'BUL'), (45, 'BUL'), (46, 'BUL'), (47, 'RUS'), (48, 'BUL'), (49, 'FRE'), (50, 'BUL'), (51, 'BUL'), (52, 'RUS'), (53, 'BUL'), (54, 'BUL'), (55, 'JPN'), (56, 'BUL'), (57, 'BUL'), (58, 'FRE'), (59, 'BUL'), (60, 'BUL'), (61, 'BUL'), (62, 'BUL'), (63, 'RUS'), (64, 'RUS'), (65, 'BUL'), (66, 'BUL'), (67, 'BUL'), (68, 'BUL'), (69, 'BUL'), (70, 'BUL'), (71, 'BUL'), (72, 'BUL'), (73, 'BUL'), (74, 'BUL'), (75, 'BUL'), (76, 'BUL'), (77, 'RUS'), (78, 'RUS'), (79, 'BUL'), (80, 'BUL'), (81, 'FRE'), (82, 'CZE'), (83, 'BUL'), (84, 'BUL'), (85, 'BUL'), (86, 'BUL'), (87, 'BUL'), (88, 'BUL'), (89, 'BUL'), (90, 'BUL'), (91, 'RUS'), (92, 'BUL'), (93, 'BUL'), (94, 'BUL'), (95, 'BUL'), (96, 'BUL'), (97, 'BUL'), (98, 'BUL'), (99, 'BUL'), (100, 'BUL'), (101, 'BUL'), (102, 'BUL'), (103, 'BUL'), (104, 'FRE'), (105, 'BUL'), (106, 'BUL'), (107, 'FRE'), (108, 'BUL'), (109, 'BUL'), (110, 'CHI'), (111, 'CHI'), (112, 'CHI'), (113, 'CHI'), (114, 'CHI'), (115, 'CHI'), (116, 'CHI'), (117, 'CHI'), (118, 'CHI'), (119, 'CHI'), (120, 'CHI'), (121, 'CHI'), (122, 'CHI'), (123, 'CHI'), (124, 'CHI'), (125, 'CHI'), (126, 'CHI'), (127, 'CHI'), (128, 'CHI'), (129, 'CHI'), (130, 'CHI'), (131, 'CHI'), (132, 'CHI'), (133, 'CHI'), (134, 'CHI'), (135, 'CHI'), (136, 'CHI'), (137, 'CHI'), (138, 'CHI'), (139, 'CHI'), (140, 'CHI'), (141, 'CHI'), (142, 'CHI'), (143, 'CHI'), (144, 'CHI'), (145, 'CHI'), (146, 'CHI'), (147, 'CHI'), (148, 'CHI'), (149, 'CHI'), (150, 'CHI'), (151, 'CHI'), (152, 'CHI'), (153, 'CHI'), (154, 'CHI'), (155, 'CHI'), (156, 'CHI'), (157, 'CHI'), (158, 'CHI'), (159, 'CHI'), (160, 'CHI'), (161, 'CHI'), (162, 'CHI'), (163, 'CHI'), (164, 'CHI'), (165, 'CHI'), (166, 'CHI'), (167, 'SPA'), (168, 'CHI'), (169, 'CHI'), (170, 'CHI'), (171, 'CHI'), (172, 'CHI'), (173, 'CHI'), (174, 'CHI'), (175, 'CHI'), (176, 'CHI'), (177, 'CHI'), (178, 'CHI'), (179, 'CHI'), (180, 'CHI'), (181, 'CHI'), (182, 'CHI'), (183, 'CHI'), (184, 'CZE'), (185, 'CHI'), (186, 'SPA'), (187, 'CHI'), (188, 'CHI'), (189, 'CHI'), (190, 'CHI'), (191, 'CHI'), (192, 'CHI'), (193, 'BUL'), (194, 'CHI'), (195, 'CHI'), (196, 'CHI'), (197, 'JPN'), (198, 'CHI'), (199, 'CHI'), (200, 'CHI'), (201, 'CHI'), (202, 'CHI'), (203, 'CHI'), (204, 'CHI'), (205, 'CHI'), (206, 'CHI'), (207, 'CHI'), (208, 'CHI'), (209, 'CHI'), (210, 'CHI'), (211, 'CHI'), (212, 'CHI'), (213, 'CHI'), (214, 'CHI'), (215, 'CHI'), (216, 'CHI'), (217, 'CHI'), (218, 'CHI'), (219, 'CHI'), (220, 'RUS'), (221, 'CZE'), (222, 'CZE'), (223, 'CZE'), (224, 'CZE'), (225, 'CZE'), (226, 'CZE'), (227, 'CZE'), (228, 'CZE'), (229, 'CZE'), (230, 'FRE'), (231, 'CZE'), (232, 'FRE'), (233, 'CZE'), (234, 'CZE'), (235, 'JPN'), (236, 'RUS'), (237, 'CZE'), (238, 'CZE'), (239, 'FRE'), (240, 'CZE'), (241, 'CZE'), (242, 'RUS'), (243, 'CZE'), (244, 'CZE'), (245, 'CZE'), (246, 'CZE'), (247, 'RUS'), (248, 'CZE'), (249, 'CZE'), (250, 'CZE'), (251, 'CZE'), (252, 'FRE'), (253, 'CZE'), (254, 'CZE'), (255, 'CZE'), (256, 'CZE'), (257, 'CZE'), (258, 'CZE'), (259, 'CZE'), (260, 'BUL'), (261, 'FRE'), (262, 'CZE'), (263, 'CZE'), (264, 'CZE'), (265, 'CZE'), (266, 'CZE'), (267, 'CZE'), (268, 'CZE'), (269, 'CZE'), (270, 'BUL'), (271, 'CZE'), (272, 'CZE'), (273, 'CZE'), (274, 'CZE'), (275, 'CZE'), (276, 'CZE'), (277, 'CZE'), (278, 'CZE'), (279, 'CZE'), (280, 'FRE'), (281, 'CZE'), (282, 'CZE'), (283, 'BUL'), (284, 'RUS'), (285, 'CZE'), (286, 'RUS'), (287, 'CZE'), (288, 'RUS'), (289, 'CZE'), (290, 'CZE'), (291, 'CZE'), (292, 'CZE'), (293, 'CZE'), (294, 'FRE'), (295, 'CZE'), (296, 'SPA'), (297, 'SPA'), (298, 'CZE'), (299, 'CZE'), (300, 'CZE'), (301, 'CZE'), (302, 'CZE'), (303, 'RUS'), (304, 'SPA'), (305, 'CZE'), (306, 'CZE'), (307, 'CZE'), (308, 'CZE'), (309, 'CZE'), (310, 'CZE'), (311, 'CZE'), (312, 'FRE'), (313, 'CZE'), (314, 'CHI'), (315, 'CHI'), (316, 'CZE'), (317, 'CZE'), (318, 'FRE'), (319, 'BUL'), (320, 'CZE'), (321, 'RUS'), (322, 'FRE'), (323, 'CZE'), (324, 'CZE'), (325, 'CZE'), (326, 'RUS'), (327, 'RUS'), (328, 'CZE'), (329, 'CZE'), (330, 'SPA'), (331, 'FRE'), (332, 'SPA'), (333, 'CZE'), (334, 'FRE'), (335, 'FRE'), (336, 'SPA'), (337, 'FRE'), (338, 'SPA'), (339, 'FRE'), (340, 'FRE'), (341, 'FRE'), (342, 'FRE'), (343, 'FRE'), (344, 'FRE'), (345, 'SPA'), (346, 'JPN'), (347, 'FRE'), (348, 'FRE'), (349, 'BUL'), (350, 'FRE'), (351, 'BUL'), (352, 'FRE'), (353, 'BUL'), (354, 'FRE'), (355, 'BUL'), (356, 'FRE'), (357, 'FRE'), (358, 'FRE'), (359, 'FRE'), (360, 'FRE'), (361, 'FRE'), (362, 'FRE'), (363, 'FRE'), (364, 'FRE'), (365, 'FRE'), (366, 'FRE'), (367, 'FRE'), (368, 'FRE'), (369, 'FRE'), (370, 'FRE'), (371, 'FRE'), (372, 'FRE'), (373, 'FRE'), (374, 'FRE'), (375, 'FRE'), (376, 'FRE'), (377, 'FRE'), (378, 'FRE'), (379, 'FRE'), (380, 'FRE'), (381, 'FRE'), (382, 'FRE'), (383, 'FRE'), (384, 'FRE'), (385, 'FRE'), (386, 'FRE'), (387, 'FRE'), (388, 'FRE'), (389, 'FRE'), (390, 'FRE'), (391, 'FRE'), (392, 'FRE'), (393, 'FRE'), (394, 'FRE'), (395, 'FRE'), (396, 'FRE'), (397, 'FRE'), (398, 'FRE'), (399, 'FRE'), (400, 'FRE'), (401, 'FRE'), (402, 'SPA'), (403, 'FRE'), (404, 'RUS'), (405, 'FRE'), (406, 'FRE'), (407, 'FRE'), (408, 'FRE'), (409, 'FRE'), (410, 'FRE'), (411, 'FRE'), (412, 'SPA'), (413, 'CZE'), (414, 'FRE'), (415, 'BUL'), (416, 'FRE'), (417, 'FRE'), (418, 'FRE'), (419, 'FRE'), (420, 'RUS'), (421, 'FRE'), (422, 'FRE'), (423, 'RUS'), (424, 'FRE'), (425, 'FRE'), (426, 'FRE'), (427, 'FRE'), (428, 'SPA'), (429, 'FRE'), (430, 'FRE'), (431, 'FRE'), (432, 'FRE'), (433, 'FRE'), (434, 'FRE'), (435, 'FRE'), (436, 'FRE'), (437, 'FRE'), (438, 'FRE'), (439, 'RUS'), (440, 'JPN'), (441, 'JPN'), (442, 'JPN'), (443, 'JPN'), (444, 'JPN'), (445, 'JPN'), (446, 'JPN'), (447, 'SPA'), (448, 'JPN'), (449, 'JPN'), (450, 'JPN'), (451, 'JPN'), (452, 'JPN'), (453, 'JPN'), (454, 'JPN'), (455, 'JPN'), (456, 'JPN'), (457, 'JPN'), (458, 'JPN'), (459, 'JPN'), (460, 'JPN'), (461, 'JPN'), (462, 'JPN'), (463, 'JPN'), (464, 'JPN'), (465, 'JPN'), (466, 'JPN'), (467, 'JPN'), (468, 'JPN'), (469, 'JPN'), (470, 'JPN'), (471, 'JPN'), (472, 'JPN'), (473, 'CHI'), (474, 'JPN'), (475, 'JPN'), (476, 'CHI'), (477, 'JPN'), (478, 'JPN'), (479, 'JPN'), (480, 'JPN'), (481, 'JPN'), (482, 'JPN'), (483, 'JPN'), (484, 'JPN'), (485, 'JPN'), (486, 'JPN'), (487, 'JPN'), (488, 'JPN'), (489, 'JPN'), (490, 'JPN'), (491, 'JPN'), (492, 'JPN'), (493, 'JPN'), (494, 'CHI'), (495, 'JPN'), (496, 'JPN'), (497, 'JPN'), (498, 'JPN'), (499, 'JPN'), (500, 'JPN'), (501, 'JPN'), (502, 'JPN'), (503, 'JPN'), (504, 'JPN'), (505, 'JPN'), (506, 'JPN'), (507, 'JPN'), (508, 'JPN'), (509, 'JPN'), (510, 'JPN'), (511, 'JPN'), (512, 'JPN'), (513, 'JPN'), (514, 'JPN'), (515, 'JPN'), (516, 'JPN'), (517, 'CHI'), (518, 'JPN'), (519, 'JPN'), (520, 'JPN'), (521, 'JPN'), (522, 'CHI'), (523, 'JPN'), (524, 'JPN'), (525, 'JPN'), (526, 'JPN'), (527, 'JPN'), (528, 'JPN'), (529, 'JPN'), (530, 'JPN'), (531, 'JPN'), (532, 'JPN'), (533, 'JPN'), (534, 'JPN'), (535, 'JPN'), (536, 'JPN'), (537, 'JPN'), (538, 'JPN'), (539, 'JPN'), (540, 'CHI'), (541, 'JPN'), (542, 'JPN'), (543, 'JPN'), (544, 'JPN'), (545, 'JPN'), (546, 'JPN'), (547, 'JPN'), (548, 'JPN'), (549, 'JPN'), (550, 'RUS'), (551, 'FRE'), (552, 'CZE'), (553, 'BUL'), (554, 'RUS'), (555, 'FRE'), (556, 'RUS'), (557, 'RUS'), (558, 'BUL'), (559, 'BUL'), (560, 'RUS'), (561, 'FRE'), (562, 'FRE'), (563, 'RUS'), (564, 'FRE'), (565, 'RUS'), (566, 'RUS'), (567, 'RUS'), (568, 'RUS'), (569, 'RUS'), (570, 'FRE'), (571, 'RUS'), (572, 'RUS'), (573, 'FRE'), (574, 'RUS'), (575, 'RUS'), (576, 'RUS'), (577, 'RUS'), (578, 'BUL'), (579, 'RUS'), (580, 'RUS'), (581, 'RUS'), (582, 'BUL'), (583, 'RUS'), (584, 'RUS'), (585, 'RUS'), (586, 'RUS'), (587, 'BUL'), (588, 'RUS'), (589, 'RUS'), (590, 'RUS'), (591, 'RUS'), (592, 'BUL'), (593, 'FRE'), (594, 'SPA'), (595, 'RUS'), (596, 'CZE'), (597, 'FRE'), (598, 'RUS'), (599, 'BUL'), (600, 'RUS'), (601, 'CZE'), (602, 'RUS'), (603, 'RUS'), (604, 'RUS'), (605, 'BUL'), (606, 'RUS'), (607, 'RUS'), (608, 'RUS'), (609, 'BUL'), (610, 'FRE'), (611, 'SPA'), (612, 'RUS'), (613, 'CZE'), (614, 'SPA'), (615, 'RUS'), (616, 'RUS'), (617, 'RUS'), (618, 'SPA'), (619, 'CZE'), (620, 'RUS'), (621, 'RUS'), (622, 'RUS'), (623, 'RUS'), (624, 'RUS'), (625, 'RUS'), (626, 'RUS'), (627, 'SPA'), (628, 'RUS'), (629, 'RUS'), (630, 'RUS'), (631, 'CHI'), (632, 'JPN'), (633, 'RUS'), (634, 'CZE'), (635, 'RUS'), (636, 'RUS'), (637, 'JPN'), (638, 'RUS'), (639, 'RUS'), (640, 'RUS'), (641, 'CZE'), (642, 'RUS'), (643, 'RUS'), (644, 'RUS'), (645, 'RUS'), (646, 'RUS'), (647, 'RUS'), (648, 'RUS'), (649, 'RUS'), (650, 'RUS'), (651, 'RUS'), (652, 'RUS'), (653, 'RUS'), (654, 'RUS'), (655, 'CZE'), (656, 'RUS'), (657, 'RUS'), (658, 'RUS'), (659, 'RUS'), (660, 'SPA'), (661, 'SPA'), (662, 'BUL'), (663, 'SPA'), (664, 'FRE'), (665, 'SPA'), (666, 'RUS'), (667, 'RUS'), (668, 'BUL'), (669, 'SPA'), (670, 'CZE'), (671, 'FRE'), (672, 'SPA'), (673, 'FRE'), (674, 'SPA'), (675, 'FRE'), (676, 'FRE'), (677, 'BUL'), (678, 'SPA'), (679, 'SPA'), (680, 'SPA'), (681, 'SPA'), (682, 'CZE'), (683, 'SPA'), (684, 'FRE'), (685, 'SPA'), (686, 'SPA'), (687, 'SPA'), (688, 'SPA'), (689, 'CZE'), (690, 'SPA'), (691, 'SPA'), (692, 'BUL'), (693, 'SPA'), (694, 'SPA'), (695, 'CZE'), (696, 'SPA'), (697, 'SPA'), (698, 'SPA'), (699, 'SPA'), (700, 'SPA'), (701, 'CZE'), (702, 'SPA'), (703, 'CZE'), (704, 'SPA'), (705, 'FRE'), (706, 'SPA'), (707, 'SPA'), (708, 'FRE'), (709, 'BUL'), (710, 'SPA'), (711, 'SPA'), (712, 'RUS'), (713, 'SPA'), (714, 'SPA'), (715, 'SPA'), (716, 'SPA'), (717, 'SPA'), (718, 'SPA'), (719, 'SPA'), (720, 'SPA'), (721, 'SPA'), (722, 'SPA'), (723, 'RUS'), (724, 'SPA'), (725, 'SPA'), (726, 'SPA'), (727, 'SPA'), (728, 'FRE'), (729, 'FRE'), (730, 'SPA'), (731, 'SPA'), (732, 'JPN'), (733, 'FRE'), (734, 'SPA'), (735, 'CZE'), (736, 'FRE'), (737, 'SPA'), (738, 'SPA'), (739, 'SPA'), (740, 'FRE'), (741, 'SPA'), (742, 'FRE'), (743, 'CZE'), (744, 'SPA'), (745, 'SPA'), (746, 'FRE'), (747, 'SPA'), (748, 'SPA'), (749, 'SPA'), (750, 'SPA'), (751, 'SPA'), (752, 'CZE'), (753, 'FRE'), (754, 'SPA'), (755, 'SPA'), (756, 'SPA'), (757, 'SPA'), (758, 'SPA'), (759, 'CZE'), (760, 'CZE'), (761, 'FRE'), (762, 'SPA'), (763, 'FRE'), (764, 'SPA'), (765, 'SPA'), (766, 'SPA'), (767, 'FRE'), (768, 'FRE'), (769, 'SPA')])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "sorted_dict = OrderedDict(sorted(predictions.items()))\n",
    "sorted_predictions = list(sorted_dict.values())\n",
    "print(sorted_dict)\n",
    "icle = \"/content/drive/MyDrive/thesis_NLI/ICLE-NLI-results.csv\"\n",
    "df = pd.read_csv(icle)\n",
    "column_name = 'preds_finetuned_bert'\n",
    "num_columns = len(df.columns)\n",
    "df.insert(num_columns, column_name, sorted_predictions)\n",
    "df.head()\n",
    "df.to_csv(icle, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
